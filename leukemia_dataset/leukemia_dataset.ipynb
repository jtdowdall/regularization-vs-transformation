{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Overview of dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was obtained from [the Broad Institute](http://portals.broadinstitute.org/cgi-bin/cancer/publications/view/43) and is stored as follows:\n",
    "\n",
    "<table border=\"2\" cellspacing=\"0\" cellpadding=\"6\" rules=\"groups\" frame=\"hsides\">\n",
    "\n",
    "\n",
    "<colgroup>\n",
    "<col  class=\"org-left\" />\n",
    "\n",
    "<col  class=\"org-left\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr>\n",
    "<th scope=\"col\" class=\"org-left\">Type of data</th>\n",
    "<th scope=\"col\" class=\"org-left\">File name</th>\n",
    "</tr>\n",
    "</thead>\n",
    "\n",
    "<tbody>\n",
    "<tr>\n",
    "<td class=\"org-left\">Training data</td>\n",
    "<td class=\"org-left\">`data_set_ALL_AML_train.txt`</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-left\">Training data class labels</td>\n",
    "<td class=\"org-left\">`ALL_vs_AML_train_set_38_sorted.cls`</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-left\">Testing data</td>\n",
    "<td class=\"org-left\">`data_set_ALL_AML_independent.txt`</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-left\">Testing data class labels</td>\n",
    "<td class=\"org-left\">`Leuk_ALL_AML.test.cls`</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Cleaning the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_training_data():\n",
    "    clean_lines = []\n",
    "    with open(\"data_set_ALL_AML_train.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        clean_lines = [l.rstrip('\\t\\n') for l in lines]\n",
    "\n",
    "    with open(\"data_set_ALL_AML_train_cleaned.txt\", \"w\") as f:\n",
    "        f.writelines('\\n'.join(clean_lines))\n",
    "\n",
    "clean_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Loading the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, scipy, pandas\n",
    "import sklearn\n",
    "import re\n",
    "\n",
    "def load_data(x_filename, y_filename):\n",
    "    df_x = pandas.read_csv(x_filename, sep=\"\\t\")\n",
    "    df_x = df_x.select(lambda x: not re.search('call\\.*', x), axis=1)\n",
    "    df_x = df_x.drop(['Gene Description', \n",
    "                      'Gene Accession Number'], axis=1)\n",
    "    df_x = df_x.T\n",
    "    x = df_x.values\n",
    "\n",
    "    with open(y_filename, \"r\") as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    data = data[1].rstrip()\n",
    "\n",
    "    y = numpy.fromstring(data, sep=\" \")\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "x_train, y_train = load_data(\"data_set_ALL_AML_train_cleaned.txt\",\n",
    "                             \"ALL_vs_AML_train_set_38_sorted.cls\")\n",
    "x_test, y_test = load_data(\"data_set_ALL_AML_independent.txt\",\n",
    "                           \"Leuk_ALL_AML.test.cls\")\n",
    "y_test = y_test[1:]  # dataset has one additional 0 at beginning, \n",
    "                     # so remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Run models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Kernelized logistic regression with L2 and L1 regularization, logistic regression with L1 regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the $\\gamma$ function of the RBF kernel (where $\\gamma = 1/(2\\sigma^2)$) we follow the heuristic choice mentioned in Gretton et al. (p. 748) of setting $\\sigma$ to equal the median distance between points of the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.kernel_ridge\n",
    "import sklearn.metrics.pairwise\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "import statistics\n",
    "\n",
    "#import tabulate\n",
    "\n",
    "# Calculate gamma as in Gretton et al.\n",
    "b = cdist(x_train, x_train).ravel()\n",
    "gamma = 1/(2 * pow(statistics.median(b), 2))\n",
    "\n",
    "#y_test_onehot = numpy.zeros((len(y_test), 2))\n",
    "#y_test_onehot[numpy.arange(len(y_test)), y_test.astype(int)] = 1\n",
    "\n",
    "# Calculate RBF kernel \n",
    "K      = sklearn.metrics.pairwise.rbf_kernel(x_train, x_train, gamma=gamma)\n",
    "K_test = sklearn.metrics.pairwise.rbf_kernel(x_test, x_train, gamma=gamma)\n",
    "\n",
    "# Fit kernelized logistic regression\n",
    "# (note that l2 regularization is applied by default)\n",
    "clf = sklearn.linear_model.LogisticRegression(solver='lbfgs')\n",
    "clf.fit(K, y_train)\n",
    "kernelized_l2_preds = clf.predict(K_test)\n",
    "\n",
    "# Fit kernelized logistic regression with l1 regularization\n",
    "# (note that liblinear solver used by default)\n",
    "clf = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "clf.fit(K, y_train)\n",
    "kernelized_l1_preds = clf.predict(K_test)\n",
    "\n",
    "# Fit non-kernelized logistic regression with l1 regularization\n",
    "clf = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "clf.fit(x_train, y_train)\n",
    "l1_preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation of results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "kernelized_l2_er = zero_one_loss(y_test, kernelized_l2_preds)\n",
    "kernelized_l1_er = zero_one_loss(y_test, kernelized_l1_preds)\n",
    "l1_er = zero_one_loss(y_test, l1_preds)\n",
    "\n",
    "kernelized_l2_cm = confusion_matrix(y_test, kernelized_l2_preds)\n",
    "kernelized_l1_cm = confusion_matrix(y_test, kernelized_l1_preds)\n",
    "l1_cm = confusion_matrix(y_test, l1_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# This code is a modification of code at\n",
    "# http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/svm/plot_svm_parameters_selection.html\n",
    "\n",
    "def find_svm_best_params(kernel_type):\n",
    "    C_range = 2. ** numpy.arange(-5, 15, 2)\n",
    "    gamma_range = 2. ** numpy.arange(-5, 3, 2)\n",
    "\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(kernel=kernel_type), param_grid, cv=5)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    bestparams = grid_search.best_params_\n",
    "    #results_dict = grid_search.cv_results_\n",
    "    #for param, score_mean, score_sd in zip(results_dict['params'],        \n",
    "    #results_dict['mean_test_score'], results_dict['std_test_score']):\n",
    "    #    print(param, round(score_mean, 4), round(score_sd, 4))\n",
    "    return bestparams\n",
    "\n",
    "def estimate_svm(C, gamma, kernel_type, x_train, y_train, x_test, y_test):\n",
    "    our_svm = SVC(kernel=kernel_type, C=C, gamma=gamma)\n",
    "    our_svm.fit(x_train, y_train)\n",
    "    svm_preds = our_svm.predict(x_test)\n",
    "    svm_er = zero_one_loss(y_test, svm_preds)\n",
    "    svm_cm = confusion_matrix(y_test, svm_preds)\n",
    "    return svm_er, svm_cm\n",
    "\n",
    "bestparams_rbf = find_svm_best_params(\"rbf\")\n",
    "svm_rbf_er, svm_rbf_cm = estimate_svm(bestparams_rbf['C'],\n",
    "                                      bestparams_rbf['gamma'],\n",
    "                                      \"rbf\",\n",
    "                                      x_train, y_train, x_test, y_test)\n",
    "bestparams_linear = find_svm_best_params(\"linear\")\n",
    "svm_linear_er, svm_linear_cm = estimate_svm(bestparams_linear['C'], \n",
    "                                            bestparams_linear['gamma'],\n",
    "                                            \"linear\",\n",
    "                                            x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Empirical error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kernelized L2</td>\n",
       "      <td>0.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kernelized L1</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Empirical error\n",
       "0        Kernelized L2         0.264706\n",
       "1        Kernelized L1         0.411765\n",
       "2                   L1         0.000000\n",
       "3     SVM (RBF kernel)         0.411765\n",
       "4  SVM (Linear kernel)         0.029412"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import pandas\n",
    "\n",
    "results_df = pandas.DataFrame(columns=('Model', 'Empirical error'))\n",
    "\n",
    "series_index = [\"Model\", \"Empirical error\"]\n",
    "results_df = results_df.append(pandas.Series([\"Kernelized L2\", \n",
    "                                             kernelized_l2_er], \n",
    "                                index=series_index),\n",
    "                  ignore_index=True)\n",
    "\n",
    "results_df = results_df.append(pandas.Series([\"Kernelized L1\", \n",
    "                                              kernelized_l1_er], \n",
    "                                index=series_index),\n",
    "                  ignore_index=True)\n",
    "\n",
    "results_df = results_df.append(pandas.Series([\"L1\", l1_er], \n",
    "                                index=series_index),\n",
    "                  ignore_index=True)\n",
    "\n",
    "results_df = results_df.append(pandas.Series([\"SVM (RBF kernel)\", \n",
    "                                              svm_rbf_er], \n",
    "                                             index=series_index),\n",
    "                  ignore_index=True)\n",
    "results_df = results_df.append(pandas.Series([\"SVM (Linear kernel)\", \n",
    "                                              svm_linear_er], \n",
    "                                             index=series_index),\n",
    "                  ignore_index=True)\n",
    "\n",
    "#display(HTML(results_df.to_html()))\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# References (move to separate file later)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gretton, Arthur et al. 2012. \"A Kernel Two-Sample Test.\" *Journal of Machine Learning Research*. Vol 13, p. 723-773.\n",
    "\n",
    "Hsu, Chih-Wei et al. 2016. \"A Practical Guide to Support Vector Classification.\" Department of Computer Science, National Taiwan University.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
