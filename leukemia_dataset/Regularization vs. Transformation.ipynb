{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was obtained from [the Broad Institute](http://portals.broadinstitute.org/cgi-bin/cancer/publications/view/43) and is stored as follows:\n",
    "\n",
    "<table border=\"2\" cellspacing=\"0\" cellpadding=\"6\" rules=\"groups\" frame=\"hsides\">\n",
    "\n",
    "\n",
    "<colgroup>\n",
    "<col  class=\"org-left\" />\n",
    "\n",
    "<col  class=\"org-left\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr>\n",
    "<th scope=\"col\" class=\"org-left\">Type of data</th>\n",
    "<th scope=\"col\" class=\"org-left\">File name</th>\n",
    "</tr>\n",
    "</thead>\n",
    "\n",
    "<tbody>\n",
    "<tr>\n",
    "<td class=\"org-left\">Training data</td>\n",
    "<td class=\"org-left\">`data_set_ALL_AML_train.txt`</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-left\">Training data class labels</td>\n",
    "<td class=\"org-left\">`ALL_vs_AML_train_set_38_sorted.cls`</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-left\">Testing data</td>\n",
    "<td class=\"org-left\">`data_set_ALL_AML_independent.txt`</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-left\">Testing data class labels</td>\n",
    "<td class=\"org-left\">`Leuk_ALL_AML.test.cls`</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_training_data():\n",
    "    clean_lines = []\n",
    "    with open(\"data_set_ALL_AML_train.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        clean_lines = [l.rstrip('\\t\\n') for l in lines]\n",
    "\n",
    "    with open(\"data_set_ALL_AML_train_cleaned.txt\", \"w\") as f:\n",
    "        f.writelines('\\n'.join(clean_lines))\n",
    "\n",
    "clean_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: 'select' is deprecated and will be removed in a future release. You can use .loc[labels.map(crit)] as a replacement\n  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import scipy, pandas\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "import sklearn\n",
    "import re\n",
    "\n",
    "def load_data(X_filename, y_filename):\n",
    "    df_X = pandas.read_csv(X_filename, sep=\"\\t\")\n",
    "    df_X = df_X.select(lambda x: not re.search('call\\.*', x), axis=1)\n",
    "    df_X = df_X.drop(['Gene Description', \n",
    "                      'Gene Accession Number'], axis=1)\n",
    "    df_X = df_X.T\n",
    "    X = df_X.values\n",
    "\n",
    "    with open(y_filename, \"r\") as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    data = data[1].rstrip()\n",
    "\n",
    "    y = np.fromstring(data, sep=\" \")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = load_data(\"data_set_ALL_AML_train_cleaned.txt\",\n",
    "                             \"ALL_vs_AML_train_set_38_sorted.cls\")\n",
    "X_test, y_test = load_data(\"data_set_ALL_AML_independent.txt\",\n",
    "                           \"Leuk_ALL_AML.test.cls\")\n",
    "y_test = y_test[1:]  # dataset has one additional 0 at beginning, \n",
    "                     # so remove it\n",
    "datasets['leukemia'] = [X_train,X_test,y_train,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X = df(mnist.data)\n",
    "y = df(mnist.target)\n",
    "X['label'] = y\n",
    "X.head()\n",
    "X = X[(X['label']==0.0) | (X['label']==1.0)]\n",
    "datasets['mnist'] = train_test_split(X.drop('label',1),X['label'], test_size=0.2, random_state=42)\n",
    "#datasets['mnist'] = train_test_split(datasets['mnist'][1],datasets['mnist'][3], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult dataset\n",
    "from adult_dataset import AdultDataSet\n",
    "\n",
    "\n",
    "ads_train = AdultDataSet()\n",
    "ads_test = AdultDataSet()\n",
    "ads_train.read_in_dataset(\"../AdultDataSet/adult_data.txt\")\n",
    "ads_test.read_in_dataset(\"../AdultDataSet/adult_testData.txt\")\n",
    "train_data, train_labels = ads_train.convert_data_to_numpy_array()\n",
    "test_data, test_labels = ads_test.convert_data_to_numpy_array()\n",
    "datasets[\"adult\"] = [train_data, test_data, train_labels.ravel(), test_labels.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilt dataset\n",
    "from wilt_dataset import WiltDataSet\n",
    "\n",
    "\n",
    "wds_train = WiltDataSet()\n",
    "wds_test = WiltDataSet()\n",
    "wds_train.read_in_dataset(\"../WiltDataSet/training.txt\")\n",
    "wds_test.read_in_dataset(\"../WiltDataSet/testing.txt\")\n",
    "tr_data, tr_labels = wds_train.convert_data_to_numpy_array()\n",
    "te_data, te_labels = wds_test.convert_data_to_numpy_array()\n",
    "datasets[\"wilt\"] = [tr_data, tr_labels, te_data.ravel(), te_labels.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "To choose the $\\gamma$ function of the RBF kernel (where $\\gamma = 1/(2\\sigma^2)$) we follow the heuristic choice mentioned in Gretton et al. (p. 748) of setting $\\sigma$ to equal the median distance between points of the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.kernel_ridge\n",
    "import sklearn.metrics.pairwise\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from scipy.spatial.distance import cdist\n",
    "import statistics\n",
    "\n",
    "def estimate_log_regression(X_train, X_test, y_train, y_test, \n",
    "                            kernelize=False, penalty='l2'):\n",
    "    if kernelize == True:      \n",
    "        # Calculate gamma as in Gretton et al.\n",
    "        b = cdist(X_train, X_train).ravel()\n",
    "        gamma = 1/(2 * pow(statistics.median(b), 2))\n",
    "        # Transform data via RBF kernel \n",
    "        K_train = sklearn.metrics.pairwise.rbf_kernel(X_train, X_train, gamma=gamma)\n",
    "        X_test = sklearn.metrics.pairwise.rbf_kernel(X_test, X_train, gamma=gamma)\n",
    "        X_train = K_train\n",
    "    # Fit logistic regression\n",
    "    clf = sklearn.linear_model.LogisticRegression(penalty=penalty)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    err = zero_one_loss(y_test, y_pred)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    return {'error' : err, 'confusion' : conf_mat}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# This code is a modification of code at\n",
    "# http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/svm/plot_svm_parameters_selection.html\n",
    "\n",
    "def find_svm_best_params(X_train, y_train, kernel_type):\n",
    "    C_range = 2. ** np.arange(-5, 15, 2)\n",
    "    b = cdist(X_train, X_train).ravel()\n",
    "    gamma = 1/(2 * pow(statistics.median(b), 2))\n",
    "    gamma_range = np.array([gamma])\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    grid_search = GridSearchCV(SVC(kernel=kernel_type), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    bestparams = grid_search.best_params_\n",
    "    return bestparams\n",
    "\n",
    "def estimate_svm(X_train, X_test, y_train, y_test, kernel_type):\n",
    "    bestparams = find_svm_best_params(X_train, y_train, kernel_type)\n",
    "    our_svm = SVC(kernel=kernel_type, C=bestparams['C'], gamma=bestparams['gamma'])\n",
    "    our_svm.fit(X_train, y_train)\n",
    "    y_pred = our_svm.predict(X_test)\n",
    "    err = zero_one_loss(y_test, y_pred)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    return {'error' : err, 'confusion' : conf_mat}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    return {\n",
    "        'logistic_l1' : estimate_log_regression(X_train, X_test, y_train, y_test, \n",
    "                                                penalty='l1'),\n",
    "        'logistic_l2' : estimate_log_regression(X_train, X_test, y_train, y_test),\n",
    "        'logistic_l1_rbf' : estimate_log_regression(X_train, X_test, y_train, y_test,  \n",
    "                                                penalty='l1', kernelize=True),\n",
    "        'logistic_l2_rbf' : estimate_log_regression(X_train, X_test, y_train, y_test, \n",
    "                                               kernelize=True),\n",
    "        'svm_rbf' : estimate_svm(X_train, X_test, y_train, y_test,  'rbf'),\n",
    "        'svm_linear' : estimate_svm(X_train, X_test, y_train, y_test,  'linear')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "def display_results(models):\n",
    "    series_index = [\"Model\", \"Empirical error\"]\n",
    "    results_df = df(columns=('Model', 'Empirical error'))\n",
    "    for m in models:\n",
    "        results_df = results_df.append(pandas.Series([m,models[m]['error']],index=series_index), \n",
    "                          ignore_index=True)\n",
    "    display(results_df.sort_values('Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leukemia Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Empirical error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_l1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_l1_rbf</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_l2</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_l2_rbf</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Empirical error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_l1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_l1_rbf</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_l2</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_l2_rbf</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Leukemia Results\")\n",
    "leukemia_models = evaluate_models(*datasets['leukemia'])\n",
    "display_results(leukemia_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Results\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST Results\")\n",
    "mnist_models = evaluate_models(*datasets['mnist'])\n",
    "display_results(mnist_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Results\n"
     ]
    }
   ],
   "source": [
    "print(\"Adult Results\")\n",
    "adult_models = evaluate_models(*datasets[\"adult\"])\n",
    "display_results(adult_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wilt Results\")\n",
    "wilt_models = evaluate_models(*datasets[\"wilt\"])\n",
    "display_results(wilt_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# References (move to separate file later)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gretton, Arthur et al. 2012. \"A Kernel Two-Sample Test.\" *Journal of Machine Learning Research*. Vol 13, p. 723-773.\n",
    "\n",
    "Hsu, Chih-Wei et al. 2016. \"A Practical Guide to Support Vector Classification.\" Department of Computer Science, National Taiwan University.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
