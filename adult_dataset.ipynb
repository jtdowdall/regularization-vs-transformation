{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class AdultData:\n",
    "    def __init__(self, a, wc, fw, e, enum, ms, o, re, ra, sex, cg, cl, hpw, nc, lc):\n",
    "        self.age = int(a)\n",
    "        self.work_class = wc\n",
    "        self.fnlwgt = int(fw)\n",
    "        self.education = e\n",
    "        self.education_num = int(enum)\n",
    "        self.marital_status = ms\n",
    "        self.occupation = o\n",
    "        self.relationship = re\n",
    "        self.race = ra\n",
    "        self.sex = sex\n",
    "        self.capital_gain = int(cg)\n",
    "        self.capital_loss = int(cl)\n",
    "        self.hours_per_week = int(hpw)\n",
    "        self.native_country = nc\n",
    "        self.labeled_class = lc\n",
    "        \n",
    "        \n",
    "class AdultDataset:\n",
    "    \"\"\"\n",
    "        This class stores a list of AdultData.\n",
    "        It also contains a mapping for the attributes that are strings to a number to make them easier to work with\n",
    "        during classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = list()\n",
    "        self.e_work_class = {\"Private\": 1, \"Self-emp-not-inc\": 2, \"Self-emp-inc\": 3, \"Federal-gov\": 4, \"Local-gov\": 5,\n",
    "                             \"State-gov\": 6, \"Without-pay\": 7, \"Never-worked\": 8, \"?\": 9}\n",
    "        self.e_education = {\"Bachelors\": 1, \"Some-college\": 2, \"11th\": 3, \"HS-grad\": 4, \"Prof-school\": 5,\n",
    "                            \"Assoc-acdm\": 6, \"Assoc-voc\": 7, \"9th\": 8, \"7th-8th\": 9, \"12th\": 10, \"Masters\": 11,\n",
    "                            \"1st-4th\": 12, \"10th\": 13, \"Doctorate\": 14, \"5th-6th\": 15, \"Preschool\": 16, \"?\": 17}\n",
    "        self.e_marital_status = {\"Married-civ-spouse\": 1, \"Divorced\": 2, \"Never-married\": 3, \"Separated\": 4,\n",
    "                                 \"Widowed\": 5, \"Married-spouse-absent\": 6, \"Married-AF-spouse\": 7, \"?\": 5}\n",
    "        self.e_occupation = {\"Tech-support\": 1, \"Craft-repair\": 2, \"Other-service\": 3, \"Sales\": 4, \"Exec-managerial\": 5,\n",
    "                             \"Prof-specialty\": 6, \"Handlers-cleaners\": 7, \"Machine-op-inspct\": 8, \"Adm-clerical\": 9,\n",
    "                             \"Farming-fishing\": 10, \"Transport-moving\": 11, \"Priv-house-serv\": 12,\n",
    "                             \"Protective-serv\": 13, \"Armed-Forces\": 14, \"?\": 15}\n",
    "        self.e_relationship = {\"Wife\": 1, \"Own-child\": 2, \"Husband\": 3, \"Not-in-family\": 4, \"Other-relative\": 5,\n",
    "                               \"Unmarried\": 6, \"?\": 7}\n",
    "        self.e_race = {\"White\": 1, \"Asian-Pac-Islander\": 2, \"Amer-Indian-Eskimo\": 3, \"Other\": 4, \"Black\": 5, \"?\": 6}\n",
    "        self.e_sex = {\"Male\": 1, \"Female\": 2, \"?\": 3}\n",
    "        self.e_native_country = {\"United-States\": 1, \"Cambodia\": 2, \"England\": 3, \"Puerto-Rico\": 4, \"Canada\": 5,\n",
    "                                 \"Germany\": 6, \"Outlying-US(Guam-USVI-etc)\": 7, \"India\": 8, \"Japan\": 9, \"Greece\": 10,\n",
    "                                 \"South\": 11, \"China\": 12, \"Cuba\": 13, \"Iran\": 14, \"Honduras\": 15, \"Philippines\": 16,\n",
    "                                 \"Italy\": 17, \"Poland\": 18, \"Jamaica\": 19, \"Vietnam\": 20, \"Mexico\": 21, \"Portugal\": 22,\n",
    "                                 \"Ireland\": 23, \"France\": 24, \"Dominican-Republic\": 25, \"Laos\": 26, \"Ecuador\": 27,\n",
    "                                 \"Taiwan\": 28, \"Haiti\": 29, \"Columbia\": 30, \"Hungary\": 31, \"Guatemala\": 32,\n",
    "                                 \"Nicaragua\": 33, \"Scotland\": 34, \"Thailand\": 35, \"Yugoslavia\": 36, \"El-Salvador\": 37,\n",
    "                                 \"Trinadad&Tobago\": 38, \"Peru\": 39, \"Hong\": 40, \"Holand-Netherlands\": 41, \"?\": 42}\n",
    "        self.e_labeled_class = {\">50K\": 1, \"<=50K\": 2}\n",
    "\n",
    "    def read_in_dataset(self, file_name):\n",
    "        \"\"\"This function reads in the adult dataset that is in file and puts it in self.data\"\"\"\n",
    "        with open(file_name, \"r\") as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line != \"\":\n",
    "                    split = line.split(sep=\",\")\n",
    "                    data_element = AdultData(split[0], split[1], split[2], split[3], split[4], split[5], split[6], split[7],\n",
    "                                             split[8], split[9], split[10], split[11], split[12], split[13], split[14])\n",
    "                    self.data.append(data_element)\n",
    "\n",
    "    def convert_data_to_numpy_array(self):\n",
    "        np_array_data = np.zeros((32561, 14))\n",
    "        np_array_class = np.zeros((32561, 1))\n",
    "        index = 0\n",
    "        for d in self.data:\n",
    "            np_array_data[index, 0] = d.age\n",
    "            np_array_data[index, 1] = self.e_work_class[d.work_class]\n",
    "            np_array_data[index, 2] = d.fnlwgt\n",
    "            np_array_data[index, 3] = self.e_education[d.education]\n",
    "            np_array_data[index, 4] = d.education_num\n",
    "            np_array_data[index, 5] = self.e_marital_status[d.marital_status]\n",
    "            np_array_data[index, 6] = self.e_occupation[d.occupation]\n",
    "            np_array_data[index, 7] = self.e_relationship[d.relationship]\n",
    "            np_array_data[index, 8] = self.e_race[d.race]\n",
    "            np_array_data[index, 9] = self.e_sex[d.sex]\n",
    "            np_array_data[index, 10] = d.capital_gain\n",
    "            np_array_data[index, 11] = d.capital_loss\n",
    "            np_array_data[index, 12] = d.hours_per_week\n",
    "            np_array_data[index, 13] = self.e_native_country[d.native_country]\n",
    "            np_array_class[index] = self.e_labeled_class[d.labeled_class]\n",
    "            index += 1\n",
    "        return np_array_data, np_array_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_train = AdultDataset()\n",
    "ads_test = AdultDataset()\n",
    "ads_train.read_in_dataset(\"AdultDataSet/adult_data.txt\")\n",
    "ads_test.read_in_dataset(\"AdultDataSet/adult_testData.txt\")\n",
    "train_data, train_classes = ads_train.convert_data_to_numpy_array()\n",
    "test_data, test_classes = ads_test.convert_data_to_numpy_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics.pairwise\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "import statistics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from IPython.display import HTML, display\n",
    "import pandas\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def calculate_the_rbf_kernel(data, t_data):\n",
    "    # Calculate gamma as in Gretton et al.\n",
    "    b = cdist(data, data).ravel()\n",
    "    gamma = 1/(2 * pow(statistics.median(b), 2))\n",
    "    \n",
    "    # Calculate RBF kernel \n",
    "    K = sklearn.metrics.pairwise.rbf_kernel(data, data, gamma=gamma)\n",
    "    K_test = sklearn.metrics.pairwise.rbf_kernel(t_data, data, gamma=gamma)\n",
    "    return K, K_test\n",
    "\n",
    "\n",
    "def fit_kernelized_l2(train_labels, test_labels, K, K_test):\n",
    "    # Fit kernelized logistic regression\n",
    "    # (note that l2 regularization is applied by default)\n",
    "    clf = sklearn.linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    "    clf.fit(K, train_labels)\n",
    "    kernelized_l2_preds = clf.predict(K_test)\n",
    "    kernelized_l2_er = zero_one_loss(test_labels, kernelized_l2_preds)\n",
    "    kernelized_l2_cm = confusion_matrix(test_labels, kernelized_l2_preds)\n",
    "    return kernelized_l2_er, kernelized_l2_cm\n",
    "\n",
    "\n",
    "def fit_kernelized_l1(train_labels, test_labels, K, K_test):\n",
    "    # Fit kernelized logistic regression with l1 regularization\n",
    "    # (note that liblinear solver used by default)\n",
    "    clf = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "    clf.fit(K, train_labels)\n",
    "    kernelized_l1_preds = clf.predict(K_test)\n",
    "    kernelized_l1_er = zero_one_loss(test_labels, kernelized_l1_preds)\n",
    "    kernelized_l1_cm = confusion_matrix(test_labels, kernelized_l1_preds)\n",
    "    return kernelized_l1_er, kernelized_l1_cm\n",
    "\n",
    "\n",
    "def fit_l1(train_data, train_labels, test_data, test_labels):\n",
    "    # Fit non-kernelized logistic regression with l1 regularization\n",
    "    clf = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "    clf.fit(train_data, train_labels)\n",
    "    l1_preds = clf.predict(test_data)\n",
    "    l1_er = zero_one_loss(test_labels, l1_preds)\n",
    "    l1_cm = confusion_matrix(test_labels, l1_preds)\n",
    "    return l1_er, l1_cm\n",
    "\n",
    "\n",
    "def fit_the_data(data, data_labels, t_data, t_data_labels):\n",
    "    K, K_test = calculate_the_rbf_kernel(data, t_data)\n",
    "    k_l2_er, k_l2_cm = fit_kernelized_l2(data_labels, t_data_labels, K, K_test)\n",
    "    k_l1_er, k_l1_cm = fit_kernelized_l1(data_labels, t_data_labels, K, K_test)\n",
    "    l1_er, l1_cm = fit_l1(data, data_labels, t_data, t_data_labels)\n",
    "    return k_l2_er, k_l2_cm, k_l1_er, k_l1_cm, l1_er, l1_cm\n",
    "\n",
    "\n",
    "def display_results(data, data_labels, t_data, t_data_labels):\n",
    "    r = fit_the_data(data, data_labels, t_data, t_data_labels)\n",
    "    results_df = pandas.DataFrame(columns=('Model', 'Empirical error'))\n",
    "    series_index = [\"Model\", \"Empirical error\"]\n",
    "    results_df = results_df.append(pandas.Series([\"Kernelized L2\", r[0]], index=series_index), ignore_index=True)\n",
    "    results_df = results_df.append(pandas.Series([\"Kernelized L1\", r[2]], index=series_index), ignore_index=True)\n",
    "    results_df = results_df.append(pandas.Series([\"L1\", r[4]], index=series_index), ignore_index=True)\n",
    "\n",
    "    # display(HTML(results_df.to_html()))\n",
    "\n",
    "    display(results_df)\n",
    "    \n",
    "    \n",
    "def svm_grid_search(data, data_label):\n",
    "    # This code is a modification of code at\n",
    "    # http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/svm/plot_svm_parameters_selection.html\n",
    "\n",
    "    C_range = 2. ** np.arange(-5, 15, 2)\n",
    "    gamma_range = 2. ** np.arange(-5, 3, 2)\n",
    "\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "    grid = GridSearchCV(estimator=SVC(), \n",
    "                    param_grid=param_grid, \n",
    "                    cv=StratifiedKFold(n_splits=5).split(data, data_label))\n",
    "\n",
    "    grid.fit(data, data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
